{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepComperssion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0JKioUfW7Um",
        "outputId": "78388d97-12ea-4ea2-fba8-499f7157a862"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade torch torchvision"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTjvXDefj2mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9274e355-1e21-4adf-c317-4a4706d9b3e2"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 26 14:25:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    73W / 149W |   2764MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTOnbLXwf-Qp"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from time import time"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMMWCpWakDG5"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA0QqF5xgSce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4815f3e-3c00-4b3d-c340-a626acc828bb"
      },
      "source": [
        "print('==> Preparing data..')\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # transforms.RandomCrop(32, padding=4),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nftb8ah1lxr8"
      },
      "source": [
        "def train(num_epoch, net, device, criterion, optimizer, dataloader):\n",
        "  net = net.train()\n",
        "  net = net.to(device)\n",
        "  criterion = criterion.to(device)\n",
        "  \n",
        "  for epoch in range(num_epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in pbar:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        train_loss += loss.data\n",
        "        outputs = outputs.argmax(dim=1)\n",
        "        correct += (targets == outputs).sum()\n",
        "        total += inputs.size(0)\n",
        "\n",
        "      pbar.set_description(f'[Epoch {epoch}] Loss: {train_loss / total:.4f}, Accuracy: {correct / total * 100:.4f}%')\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWqSWlZEpGSN"
      },
      "source": [
        "def test(net, device, criterion, dataloader):\n",
        "  net.eval()\n",
        "  net = net.to(device)\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  num_data = 0\n",
        "  cur = time()\n",
        "  \n",
        "  torch.save(net.state_dict(), \"tmp.pt\")\n",
        "  model_size = \"%.2f MB\" %(os.path.getsize(\"tmp.pt\") / 1e6)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    pbar = tqdm(dataloader, total=len(dataloader))\n",
        "    for data, target in pbar:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = net(data)\n",
        "      test_loss += criterion(output, target).data\n",
        "      output = output.argmax(dim=1)\n",
        "      correct += (target == output).sum()\n",
        "      num_data += data.size(0)\n",
        "\n",
        "      pbar.set_description(f'Test set: Average loss: {test_loss / num_data:.4f}, Accuracy: {correct / num_data * 100:.4f}%, Time cost: {time() - cur:.4f}, Model size: {model_size}')\n",
        "\n",
        "  os.remove(\"tmp.pt\")\n",
        "    "
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eoOxK3mkEWm"
      },
      "source": [
        "def pruning(net):\n",
        "  for name, module in net.named_modules():\n",
        "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "      prune.l1_unstructured(module, 'weight', amount=0.7)\n",
        "      prune.remove(module, 'weight')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-a1GRKTjs-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c2f909-0844-468c-8d64-129ff08839bd"
      },
      "source": [
        "net = models.quantization.resnet50(pretrained=True)\n",
        "\n",
        "net.fc = nn.Linear(2048, 10)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
        "epoch = 1\n",
        "\n",
        "for i in range(5):\n",
        "  train(epoch, net, device, criterion, optimizer, trainloader)\n",
        "  print(\"Before Pruning...\")\n",
        "  test(net, device, criterion, testloader)\n",
        "  pruning(net)\n",
        "  print(\"After Pruning...\")\n",
        "  test(net, device, criterion, testloader)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0 Loss: 0.0136, Accuracy: 70.0060%: 100%|██████████| 782/782 [02:02<00:00,  6.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0085, Accuracy: 81.2300%, Time cost: 7.4376, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0225, Accuracy: 49.5300%, Time cost: 7.4069, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.62it/s]\n",
            "Epoch 0 Loss: 0.0087, Accuracy: 81.2900%: 100%|██████████| 782/782 [02:04<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0081, Accuracy: 82.2600%, Time cost: 7.3360, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0113, Accuracy: 76.6700%, Time cost: 7.3624, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.72it/s]\n",
            "Epoch 0 Loss: 0.0070, Accuracy: 84.7900%: 100%|██████████| 782/782 [02:04<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0077, Accuracy: 83.6800%, Time cost: 7.4134, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0085, Accuracy: 82.3000%, Time cost: 7.3398, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.92it/s]\n",
            "Epoch 0 Loss: 0.0058, Accuracy: 87.2920%: 100%|██████████| 782/782 [02:04<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0076, Accuracy: 83.5300%, Time cost: 7.4562, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0075, Accuracy: 83.7100%, Time cost: 7.2901, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 22.12it/s]\n",
            "Epoch 0 Loss: 0.0047, Accuracy: 89.8080%: 100%|██████████| 782/782 [02:04<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0076, Accuracy: 84.1100%, Time cost: 7.3470, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test set: Average loss: 0.0070, Accuracy: 85.0300%, Time cost: 7.4521, Model size: 94.43 MB: 100%|██████████| 157/157 [00:07<00:00, 21.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEk4trTvWTh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878cb6d5-d117-4152-8151-1c02c4c92319"
      },
      "source": [
        "net.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "net.fuse_model()\n",
        "net = torch.quantization.prepare_qat(net)\n",
        "train(epoch, net, device, criterion, optimizer, trainloader)\n",
        "pruning(net)\n",
        "\n",
        "# models.quantization.utils.quantize_model(net, \"fbgemm\")\n",
        "test(net, 'cpu', criterion, testloader)\n",
        "torch.quantization.convert(net, inplace=True)\n",
        "test(net, 'cpu', criterion, testloader)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/ao/quantization/observer.py:174: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
            "Epoch 0 Loss: 0.0026, Accuracy: 96.4960%: 100%|██████████| 782/782 [02:29<00:00,  5.23it/s]\n",
            "Test set: Average loss: 0.0070, Accuracy: 85.0700%, Time cost: 159.2476, Model size: 94.78 MB: 100%|██████████| 157/157 [02:39<00:00,  1.01s/it]\n",
            "Test set: Average loss: 0.0070, Accuracy: 84.9600%, Time cost: 32.4488, Model size: 24.12 MB: 100%|██████████| 157/157 [00:32<00:00,  4.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP1JtjwzZX2H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}